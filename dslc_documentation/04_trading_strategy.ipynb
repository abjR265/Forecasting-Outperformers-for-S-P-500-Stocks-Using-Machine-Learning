{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment: a trading strategy\n",
    "> **Warning!** Please run `01_cleaning.ipynb` and `03_prediction.ipynb` first if you haven't already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functions.constants import BM_NAME, STARTDATE, ENDDATE, N_THRESHOLD_BPS, DATA_DIR, EVAL_START_DATE, TEST_START_DATE  # noqa: F401\n",
    "\n",
    "from functions.helper_fns import remove_BBG_suffixes, melt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_period = \"1w\"\n",
    "optimum_model_name = \"Stacking\"\n",
    "eval_dataset_mode = False\n",
    "\n",
    "predictions_path = f\"{DATA_DIR}/{BM_NAME}_eval_predictions_{optimum_model_name}.csv\" if eval_dataset_mode else f\"{DATA_DIR}/{BM_NAME}_{chosen_period}_outperformance_predictions_{optimum_model_name}.csv\"\n",
    "predictions = pd.read_csv(predictions_path,parse_dates=[\"Date\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_dataset_mode:\n",
    "    predictions_test = predictions\n",
    "else:\n",
    "    predictions_train_and_eval = predictions[predictions.Date < TEST_START_DATE] #not spectacularly useful but good for debugging\n",
    "    predictions_test = predictions[predictions.Date >= TEST_START_DATE]\n",
    "    predictions_test\n",
    "(predictions_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load prices by ticker and by BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "bm_index_prices_df_path = DATA_DIR + BM_NAME + \"_BM_prices.csv\"\n",
    "bm_holdings_prices_df_path = DATA_DIR + BM_NAME + \"_constituents_prices.csv\"\n",
    "\n",
    "def load_bm_index_df(path):\n",
    "    df = pd.read_csv(path, skiprows=3)\n",
    "    df = df.rename(columns={df.columns[0]: \"Date\"})\n",
    "    df = df[2:]\n",
    "    #ensure all cols except Date are numeric. Coerce nan if not\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    return df\n",
    "\n",
    "bm_index_prices_raw = load_bm_index_df(bm_index_prices_df_path)\n",
    "bm_holdings_prices_raw = load_bm_index_df(bm_holdings_prices_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_clean_data_for_trading(df):\n",
    "    df = remove_BBG_suffixes(df)\n",
    "    df = melt_data(df)\n",
    "    return df\n",
    "\n",
    "bm_index_prices = preprocess_and_clean_data_for_trading(bm_index_prices_raw)\n",
    "bm_holdings_prices = preprocess_and_clean_data_for_trading(bm_holdings_prices_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pricing_date = predictions_test.Date.iloc[0]\n",
    "portfolio_df_array = []\n",
    "unique_dates = predictions_test.Date.unique()\n",
    "for pricing_date in unique_dates:\n",
    "    this_date_predictions = predictions_test[predictions_test.Date == pricing_date]\n",
    "    outperform_prob_column = f\"outperform_{chosen_period}_probability\"\n",
    "    # print(\"This date predictions df\") \n",
    "    # print(this_date_predictions.head())\n",
    "    this_date_prices = bm_holdings_prices[bm_holdings_prices.Date == pricing_date]\n",
    "    #if this_date_prices is empty, use proxy_pricing_date = pricing_date - 1 biz day. Look back 5 days until we find a non-empty df\n",
    "    if not len(this_date_prices):\n",
    "        proxy_pricing_date = pricing_date\n",
    "        lookback_days = 0\n",
    "        lookback_window = 5\n",
    "        while this_date_prices.empty:\n",
    "            proxy_pricing_date = proxy_pricing_date - pd.Timedelta(days=1)\n",
    "            this_date_prices = bm_holdings_prices[bm_holdings_prices.Date == proxy_pricing_date]\n",
    "            lookback_days += 1\n",
    "            if lookback_days > lookback_window:\n",
    "                raise ValueError(f\"Could not find a non-empty prices df in the last {lookback_window} days for {pricing_date}\")\n",
    "    this_date_prices = this_date_prices.drop(columns=[\"Date\"])\n",
    "    this_date_predictions = this_date_predictions.merge(this_date_prices, on=\"Ticker\", how=\"left\")\n",
    "    #if prices are null for a ticker set the outperform probability to 0 and also outperform_1w_predicted etc to 0\n",
    "    this_date_predictions[outperform_prob_column] = this_date_predictions[outperform_prob_column].where(this_date_predictions.Price.notnull(), 0)\n",
    "    this_date_predictions[f\"outperform_{chosen_period}_predicted\"] = this_date_predictions[f\"outperform_{chosen_period}_predicted\"].where(this_date_predictions.Price.notnull(), 0)\n",
    "    probability_cutoff = 0.50\n",
    "    num_outperformers = this_date_predictions[outperform_prob_column].gt(probability_cutoff).sum()\n",
    "    print(f\"Pricing Date: {pricing_date}, outperformer count: {num_outperformers}\")\n",
    "    num_non_null_prices = this_date_predictions.Price.notnull().sum()\n",
    "    if num_outperformers == 0:\n",
    "        print(f\"No outperformers forecasted on {pricing_date}\")\n",
    "    wt_per_outperformer = 1 / num_outperformers if num_outperformers > 0 else 1 / num_non_null_prices\n",
    "    if num_outperformers > 0:\n",
    "        this_date_predictions[\"decision_port_weight\"] = this_date_predictions[outperform_prob_column].apply(lambda x: wt_per_outperformer if x > probability_cutoff else 0)\n",
    "    else:\n",
    "        #assign wt_per_outperformer to all with non-null prices\n",
    "        this_date_predictions[\"decision_port_weight\"] = this_date_predictions.Price.apply(lambda x: wt_per_outperformer if pd.notnull(x) else 0)\n",
    "        # this_date_predictions[\"decision_port_weight\"] = this_date_predictions[outperform_prob_column].apply(lambda x: wt_per_outperformer if x > probability_cutoff else 0)\n",
    "    this_date_portfolio = this_date_predictions[[\"Date\",\"Ticker\",\"decision_port_weight\",\"Price\"]]\n",
    "    # this_date_portfolio\n",
    "    portfolio_df_array.append(this_date_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed_buys_df = pd.concat(portfolio_df_array)\n",
    "proposed_buys_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extend portfolio_df with 'last_date_port_weight' and 'last_date_price' columns\n",
    "portfolio_df = pd.concat(portfolio_df_array)\n",
    "trades_df_array = []\n",
    "\n",
    "seed_capital = 1e6\n",
    "#extend with last week's held weights and prices\n",
    "# portfolio_df[\"last_date_port_weight\"] = portfolio_df.groupby(\"Ticker\")[\"decision_port_weight\"].shift(1)\n",
    "# portfolio_df[\"last_date_price\"] = portfolio_df.groupby(\"Ticker\")[\"Price\"].shift(1)\n",
    "# portfolio_df\n",
    "\n",
    "#iterate by date\n",
    "# for pricing_date in unique_dates:\n",
    "pricing_date = unique_dates[0]\n",
    "for pricing_date in unique_dates:\n",
    "    this_period_portfolio = portfolio_df[portfolio_df.Date == pricing_date]\n",
    "    #check if this is the first date (i.e. last_date_port_weight is null)\n",
    "    is_first_date = pricing_date == min(unique_dates)\n",
    "    if is_first_date:\n",
    "        this_period_portfolio['shares_buying'] = seed_capital * this_period_portfolio.decision_port_weight / this_period_portfolio.Price\n",
    "        this_period_portfolio['shares_selling'] = 0\n",
    "        this_period_portfolio['cash_flow'] = -seed_capital * this_period_portfolio.decision_port_weight\n",
    "    else:\n",
    "        #get last period from unique_dates\n",
    "        last_period = unique_dates[unique_dates < pricing_date].max()\n",
    "        last_period_portfolio = trades_df_array[-1]\n",
    "        this_period_portfolio['shares_selling'] = last_period_portfolio['shares_buying']\n",
    "        revenue_from_selling = (last_period_portfolio['shares_buying'] * this_period_portfolio['Price']).sum()\n",
    "        print(f\"Revenue from selling as of {pricing_date}: ${revenue_from_selling.sum()}\")\n",
    "        this_period_portfolio['shares_buying'] = revenue_from_selling * this_period_portfolio.decision_port_weight / this_period_portfolio.Price\n",
    "        this_period_portfolio['cash_flow'] = 0\n",
    "    this_period_portfolio['value_at_close'] = this_period_portfolio['shares_buying'] * this_period_portfolio['Price']\n",
    "    trades_df_array.append(this_period_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_df = pd.concat(trades_df_array)\n",
    "portfolio_value = trades_df.groupby(\"Date\")[\"value_at_close\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match dates to portfolio_value min and max dates\n",
    "min_date = portfolio_value.index.min()\n",
    "max_date = portfolio_value.index.max()\n",
    "bm_index_prices_test_period = bm_index_prices[(bm_index_prices.Date >= min_date) & (bm_index_prices.Date <= max_date)]\n",
    "# bm_index_prices_test_period = bm_index_prices[bm_index_prices.Date >= TEST_START_DATE]\n",
    "bm_index_prices_test_period.sort_values(\"Date\", inplace=True)\n",
    "#rescale to start at 1 million\n",
    "bm_index_prices_test_period[\"Price\"] = bm_index_prices_test_period[\"Price\"] / bm_index_prices_test_period[\"Price\"].iloc[0] * seed_capital\n",
    "num_trading_days = len(bm_index_prices_test_period)\n",
    "# Calculate the annualized return\n",
    "annualized_port_return = (portfolio_value.iloc[-1] / portfolio_value.iloc[0]) ** (252/num_trading_days) - 1\n",
    "annualized_bm_return = (bm_index_prices_test_period[\"Price\"].iloc[-1] / bm_index_prices_test_period[\"Price\"].iloc[0]) ** (252/num_trading_days) - 1\n",
    "annualized_active_return = annualized_port_return - annualized_bm_return\n",
    "print(f\"Annualized Portfolio Return: {annualized_port_return:.2%}\")\n",
    "print(f\"Annualized Benchmark Return: {annualized_bm_return:.2%}\")\n",
    "print(f\"Annualized Active Return: {annualized_active_return:.2%}\")\n",
    "portfolio_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot both make big plot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(portfolio_value, label=\"Portfolio\", color=\"blue\")\n",
    "plt.plot(bm_index_prices_test_period.Date, bm_index_prices_test_period.Price, label=\"Benchmark Index\", color=\"red\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plot_title = \"Portfolio Value vs Benchmark Index over Time (USD)\"\n",
    "if eval_dataset_mode:\n",
    "    plot_title = \"Evaluation Period: \" + plot_title\n",
    "    plot_file_path = f\"{DATA_DIR}/{BM_NAME}_plot_eval_{optimum_model_name}_port_vs_bm.png\"\n",
    "else:\n",
    "    plot_title = \"Test Period: \" + plot_title\n",
    "    plot_file_path = f\"{DATA_DIR}/{BM_NAME}_plot_test_{optimum_model_name}_port_vs_bm.png\"\n",
    "plot_title += \", using \" + optimum_model_name\n",
    "plt.title(plot_title)\n",
    "#print annualized port and bm and active returns, small font\n",
    "plt.text(0.15, 0.75, f\"Annualized Portfolio Return: {annualized_port_return:.2%}\", fontsize=9, transform=plt.gcf().transFigure)\n",
    "plt.text(0.15, 0.725, f\"Annualized Benchmark Return: {annualized_bm_return:.2%}\", fontsize=9, transform=plt.gcf().transFigure)\n",
    "plt.text(0.15, 0.7, f\"Annualized Active Return: {annualized_active_return:.2%}\", fontsize=9, transform=plt.gcf().transFigure)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(plot_file_path)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
