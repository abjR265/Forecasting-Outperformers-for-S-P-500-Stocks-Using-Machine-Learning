{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "> **Warning!** Please run `01_cleaning.ipynb` first if you haven't already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functions.constants import BM_NAME, N_THRESHOLD_BPS,DATA_DIR \n",
    "from functions.helper_fns import featurize_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_returns_path = DATA_DIR + BM_NAME + \"_active_returns.csv\"\n",
    "active_returns = pd.read_csv(active_returns_path, index_col=0, parse_dates=True)\n",
    "print(\"Loaded active returns from\", active_returns_path)\n",
    "active_returns_thresholded_path = DATA_DIR + BM_NAME + \"_active_returns_thresholded_\" + str(N_THRESHOLD_BPS) + \"bps.csv\"\n",
    "active_returns_thresholded = pd.read_csv(active_returns_thresholded_path, index_col=0, parse_dates=True)\n",
    "print(\"Loaded active returns thresholded from\", active_returns_thresholded_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previewing the thresholded data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TICKER = \"GS UN\" # Goldman Sachs--also try \"AAPL UW\" and \"JPM UN\"\n",
    "TEST_PERIODS = [\"1b\", \"1w\", \"1m\", \"1q\", \"1y\"]\n",
    "period_columns = [\"active_returns_\" + period for period in TEST_PERIODS]\n",
    "test_ticker_df = active_returns_thresholded[active_returns_thresholded[\"Ticker\"] == TEST_TICKER]\n",
    "test_ticker_df\n",
    "#True and False counts for each period \n",
    "true_counts = test_ticker_df[period_columns].sum()\n",
    "false_counts = len(test_ticker_df) - true_counts\n",
    "print(\"Col Name           || True Count || False Count\")\n",
    "for col in period_columns:\n",
    "    print(f\"{col:<18} || {true_counts[col]:<10} || {false_counts[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter for test period\n",
    "TEST_PERIOD = \"1b\"  # This can be set to different periods like \"1b\", \"1w\", \"1m\", \"1q\", \"1y\"\n",
    "shift_bizdays = 1\n",
    "#for our given TEST_TICKER let us construct a simple strategy that forecasts 1 if yesterday's active_returns_1b was 1, 0 if it was 0\n",
    "test_ticker_df = active_returns_thresholded[active_returns_thresholded[\"Ticker\"] == TEST_TICKER]\n",
    "test_ticker_df = test_ticker_df[[\"Ticker\", \"Date\", f\"active_returns_{TEST_PERIOD}\"]] \n",
    "#soort in ascending by Ticker first then Date\n",
    "test_ticker_df = test_ticker_df.sort_values([\"Ticker\", \"Date\"])\n",
    "test_ticker_df[f\"active_returns_{TEST_PERIOD}_forecast_dumb\"] = test_ticker_df[f\"active_returns_{TEST_PERIOD}\"].shift(shift_bizdays)\n",
    "#drop row where forecast column is NaN\n",
    "test_ticker_df = test_ticker_df.dropna()\n",
    "#measure precision and recall of this dumb model, get f1 score and accuracy\n",
    "true_positive = len(test_ticker_df[(test_ticker_df[f\"active_returns_{TEST_PERIOD}\"] == 1) & (test_ticker_df[f\"active_returns_{TEST_PERIOD}_forecast_dumb\"] == 1)])\n",
    "false_positive = len(test_ticker_df[(test_ticker_df[f\"active_returns_{TEST_PERIOD}\"] == 0) & (test_ticker_df[f\"active_returns_{TEST_PERIOD}_forecast_dumb\"] == 1)])\n",
    "true_negative = len(test_ticker_df[(test_ticker_df[f\"active_returns_{TEST_PERIOD}\"] == 0) & (test_ticker_df[f\"active_returns_{TEST_PERIOD}_forecast_dumb\"] == 0)])\n",
    "false_negative = len(test_ticker_df[(test_ticker_df[f\"active_returns_{TEST_PERIOD}\"] == 1) & (test_ticker_df[f\"active_returns_{TEST_PERIOD}_forecast_dumb\"] == 0)])\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print(f\"Dumb Momentum Model that forecasts +1 if previous period's active_returns_{TEST_PERIOD} was +1, 0 if it was 0. Specific to\", TEST_TICKER)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", 2 * precision * recall / (precision + recall))\n",
    "print(\"Accuracy:\", (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative))\n",
    "print(\"True Positive:\", true_positive)\n",
    "print(\"False Positive:\", false_positive)\n",
    "print(\"True Negative:\", true_negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PERIOD = \"1b\"  # This can be set to different periods like \"1b\", \"1w\", \"1m\", \"1q\", \"1y\"\n",
    "shift_bizdays = 1\n",
    "# Initialize counters for the global confusion matrix\n",
    "global_true_positive = 0\n",
    "global_false_positive = 0\n",
    "global_true_negative = 0\n",
    "global_false_negative = 0\n",
    "\n",
    "for ticker in active_returns_thresholded[\"Ticker\"].unique():\n",
    "    # Filter the data for the current ticker\n",
    "    ticker_df = active_returns_thresholded[active_returns_thresholded[\"Ticker\"] == ticker]\n",
    "    ticker_df = ticker_df[[\"Ticker\", \"Date\", f\"active_returns_{TEST_PERIOD}\"]]  # Use the TEST_PERIOD here\n",
    "    \n",
    "    # Sort by Ticker and Date\n",
    "    ticker_df = ticker_df.sort_values([\"Ticker\", \"Date\"])\n",
    "    \n",
    "    # Create forecast column based on the TEST_PERIOD\n",
    "    ticker_df[f\"active_returns_{TEST_PERIOD}_forecast_dumb\"] = ticker_df[f\"active_returns_{TEST_PERIOD}\"].shift(shift_bizdays)\n",
    "    \n",
    "    # Drop rows with NaN in forecast column\n",
    "    ticker_df = ticker_df.dropna()\n",
    "    \n",
    "    global_true_positive += len(ticker_df[(ticker_df[f\"active_returns_{TEST_PERIOD}\"] == 1) & (ticker_df[f\"active_returns_{TEST_PERIOD}_forecast_dumb\"] == 1)])\n",
    "    global_false_positive += len(ticker_df[(ticker_df[f\"active_returns_{TEST_PERIOD}\"] == 0) & (ticker_df[f\"active_returns_{TEST_PERIOD}_forecast_dumb\"] == 1)])\n",
    "    global_true_negative += len(ticker_df[(ticker_df[f\"active_returns_{TEST_PERIOD}\"] == 0) & (ticker_df[f\"active_returns_{TEST_PERIOD}_forecast_dumb\"] == 0)])\n",
    "    global_false_negative += len(ticker_df[(ticker_df[f\"active_returns_{TEST_PERIOD}\"] == 1) & (ticker_df[f\"active_returns_{TEST_PERIOD}_forecast_dumb\"] == 0)])\n",
    "\n",
    "# Calculate overall precision, recall, F1 score, and accuracy\n",
    "precision = global_true_positive / (global_true_positive + global_false_positive) if (global_true_positive + global_false_positive) != 0 else 0\n",
    "recall = global_true_positive / (global_true_positive + global_false_negative) if (global_true_positive + global_false_negative) != 0 else 0\n",
    "f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) != 0 else 0\n",
    "accuracy = (global_true_positive + global_true_negative) / (global_true_positive + global_true_negative + global_false_positive + global_false_negative)\n",
    "\n",
    "# Print the overall metrics\n",
    "print(f\"Dumb Momentum Model Forecasting Across All Tickers for period {TEST_PERIOD}:\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"True Positive:\", global_true_positive)\n",
    "print(\"False Positive:\", global_false_positive)\n",
    "print(\"True Negative:\", global_true_negative)\n",
    "print(\"False Negative:\", global_false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_returns.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized_active_returns_weekly = featurize_time_series(active_returns, \"1w\", 6)\n",
    "featurized_active_returns_weekly.sort_values([\"Ticker\", \"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is the data for ar_1w_t gaussian distributed?\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.histplot(featurized_active_returns_weekly[\"ar_1w_t\"], kde=True)\n",
    "# plt.show()\n",
    "#reduce xlim to mean +/- 3*std\n",
    "data_mean = featurized_active_returns_weekly[\"ar_1w_t\"].mean()\n",
    "data_std = featurized_active_returns_weekly[\"ar_1w_t\"].std()\n",
    "#make histplot within the range of mean +/- 3*std\n",
    "sns.histplot(featurized_active_returns_weekly[\"ar_1w_t\"],binrange=(-.3,.3),bins=100)\n",
    "# plt.xlim(data_mean - 3*data_std, data_mean + 3*data_std)\n",
    "plt.title(\"Distribution of Weekly Active Returns\")\n",
    "plt.xlabel(\"Active Return\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "#print mean and std in top left corner\n",
    "plt.text(data_mean - 1.7*data_std, 20000, f\"Mean: {data_mean:.4f}\\nStd. Dev.: {data_std:.4f}\")\n",
    "#plot line at active return = N_THRESHOLD_BPS / 10000\n",
    "plt.axvline(x=N_THRESHOLD_BPS / 10000, linestyle=\"--\",color=\"red\")\n",
    "#label this line\n",
    "plt.text(N_THRESHOLD_BPS / 10000 + 0.01, 22000, f\"{N_THRESHOLD_BPS} bps = {N_THRESHOLD_BPS/100}%\",color=\"red\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
