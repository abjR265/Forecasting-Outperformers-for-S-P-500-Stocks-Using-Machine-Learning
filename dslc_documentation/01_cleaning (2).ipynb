{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Preprocessing \n",
    "### Summary of Activity\n",
    "\n",
    "- **Load and Clean Data**:  \n",
    "  We load data for benchmark index prices and constituent prices from CSV files, ensuring numeric columns are properly formatted and the `Date` column is converted to datetime.\n",
    "  \n",
    "- **Data Cleaning**:  \n",
    "  This data originates from the Bloomberg terminal and uses BBG tickers. We remove unwanted suffixes (e.g., \" Equity\") from column names for clarity  \n",
    "  We reshape the data using `melt` to create a tidy format with columns for `Date`, `Ticker`, and `Price`.\n",
    "  \n",
    "- **Date Range Filtering**:  \n",
    "  We filter the data to include only rows within a specified date range (e.g.`1 Jan 2015` to `30 Sep 2024`).\n",
    "\n",
    "- **Return Calculation**:  \n",
    "  We extend the dataframe by calculating returns for various periods (1 business day, 1 week, 1 month, 1 quarter, and 1 year), handling missing values using a lookback window of 5 business days.\n",
    "  \n",
    "- **Data Merging**:  \n",
    "  We merge the benchmark and constituent data to compute active returns by subtracting benchmark returns from constituent returns.\n",
    "\n",
    "- **Validation**:  \n",
    "  We verify that the active returns sum correctly by checking if the `active_returns` plus benchmark returns equals the total return.\n",
    "  \n",
    "\n",
    "- **Final Output**:  \n",
    "  We save the cleaned, processed, and thresholded active returns to CSV files for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas.tseries.offsets import BDay, Week, MonthEnd, QuarterEnd, YearEnd\n",
    "from functions.constants import BM_NAME, STARTDATE, ENDDATE, N_THRESHOLD_BPS, DATA_DIR\n",
    "from functions.helper_fns import remove_BBG_suffixes, melt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "bm_index_prices_df_path = DATA_DIR + BM_NAME + \"_BM_prices.csv\"\n",
    "bm_holdings_prices_df_path = DATA_DIR + BM_NAME + \"_constituents_prices.csv\"\n",
    "\n",
    "def load_bm_index_df(path):\n",
    "    df = pd.read_csv(path, skiprows=3)\n",
    "    df = df.rename(columns={df.columns[0]: \"Date\"})\n",
    "    df = df[2:]\n",
    "    #ensure all cols except Date are numeric. Coerce nan if not\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    return df\n",
    "\n",
    "bm_index_prices = load_bm_index_df(bm_index_prices_df_path)\n",
    "bm_holdings_prices = load_bm_index_df(bm_holdings_prices_df_path)\n",
    "print(\"Raw data: BM prices\")\n",
    "print(bm_index_prices.head())\n",
    "print(\"Raw data: BM holdings prices\")\n",
    "print(bm_holdings_prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date_range(df, start_date=STARTDATE, end_date=ENDDATE):\n",
    "    \"\"\"\n",
    "    Filter the dataframe to keep only the rows within the specified date range\n",
    "    \"\"\"\n",
    "    df = df[(df[\"Date\"] >= start_date) & (df[\"Date\"] <= end_date)]\n",
    "    return df\n",
    "\n",
    "def extend_with_returns(df, periods=[\"1b\"], lookback_window='5b'):\n",
    "    '''\n",
    "    Extend the input dataframe with additional return columns for specified periods.\n",
    "    Handles holidays and missing data by looking back up to a defined number of business days.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input dataframe containing at least 'Date', 'Ticker', and 'Price' columns.\n",
    "    periods : list, optional, default=[\"1b\"]\n",
    "        A list of periods for which returns are calculated. Supported values include:\n",
    "        '1b' (1 business day), '1w' (1 week), '1m' (1 month), '1q' (1 quarter), '1y' (1 year), \n",
    "        NOT YET SUPPORTED: 'mtd' (month-to-date), 'qtd' (quarter-to-date), 'ytd' (year-to-date).\n",
    "    lookback_window : str, optional, default='5b'\n",
    "        The lookback window for calculating returns when frequency-based returns are unavailable. \n",
    "        The default is 5 business days.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        A new dataframe with additional columns for each specified return period (e.g., 'returns_1b', 'returns_mtd').\n",
    "    '''\n",
    "    # Ensure Date column is datetime and set it as index\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    # Sort the dataframe by Date and Ticker\n",
    "    df = df.sort_index().sort_values('Ticker')\n",
    "    \n",
    "    # Define offset mappings for supported periods\n",
    "    offset_map = {\n",
    "        '1b': BDay(1),\n",
    "        '1w': Week(1),\n",
    "        '1m': MonthEnd(1),\n",
    "        '1q': QuarterEnd(1),\n",
    "        '1y': YearEnd(1)\n",
    "    }\n",
    "    # Extract number of business days from the lookback_window\n",
    "    lookback_periods = int(lookback_window[:-1])  # Remove the 'b' and convert to int\n",
    "    lookback_offset = BDay(lookback_periods)\n",
    "\n",
    "    for period in periods:\n",
    "        t = time.time()\n",
    "        if period in offset_map:\n",
    "            offset = offset_map[period]\n",
    "            # Calculate returns based on standard periods\n",
    "            df[f'returns_{period}'] = df.groupby('Ticker')['Price'].apply(\n",
    "                lambda x: x.pct_change(freq=offset).fillna(x.pct_change(freq=lookback_offset))\n",
    "            )\n",
    "        else:\n",
    "            # For non-standard periods, apply lookback window logic\n",
    "            df[f'returns_{period}'] = df.groupby('Ticker')['Price'].apply(\n",
    "                lambda x: x.pct_change(periods=lookback_periods).fillna(x.pct_change(periods=lookback_periods))\n",
    "            )\n",
    "        # Handling missing longer returns with a rolling window (e.g., '1w', '1m')\n",
    "        if period in ['1w', '1m', '1q', '1y']:\n",
    "            df[f'returns_{period}'] = df.groupby('Ticker')[f'returns_{period}'].fillna(method='ffill')\n",
    "        print(\"Calculating returns for period:\", period, \"took\", time.time() - t, \"seconds\")\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def preprocess_and_clean_data(df):\n",
    "    t = time.time()\n",
    "    df = remove_BBG_suffixes(df)\n",
    "    print(f\"Time taken to remove BBG suffixes: {time.time() - t:.6f} seconds\")\n",
    "    t = time.time()\n",
    "    df = melt_data(df)\n",
    "    print(f\"Time taken to melt data: {time.time() - t:.6f} seconds\")\n",
    "    t = time.time()\n",
    "    df = extend_with_returns(df, periods=[\"1b\",\"1w\", \"1m\", \"1q\", \"1y\"])\n",
    "    print(f\"Time taken to extend with returns: {time.time() - t:.6f} seconds\")\n",
    "    t = time.time()\n",
    "    df = filter_date_range(df)\n",
    "    print(f\"Time taken to filter date range: {time.time() - t:.6f} seconds\")\n",
    "    return df\n",
    "\n",
    "bm_index_prices_preproc = preprocess_and_clean_data(bm_index_prices)\n",
    "print(\"Preprocessed data: BM prices\")\n",
    "print(bm_index_prices_preproc.head())\n",
    "bm_holdings_prices_preproc = preprocess_and_clean_data(bm_holdings_prices)\n",
    "print(\"Preprocessed data: BM holdings prices\")\n",
    "print(bm_holdings_prices_preproc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print percentage of missing in each column\n",
    "print(\"After having handled missing values due to holidays and weekends:\\n\")\n",
    "print(\"Fraction of missing values in BM index prices:\")\n",
    "print(bm_index_prices_preproc.isnull().mean())\n",
    "print(\"Fraction of missing values in BM holdings prices:\")\n",
    "print(bm_holdings_prices_preproc.isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_returns(bm_index_prices, bm_holdings_prices):\n",
    "    #establish a safe local scope\n",
    "    bm_index_prices = bm_index_prices.copy()\n",
    "    bm_holdings_prices = bm_holdings_prices.copy()\n",
    "\n",
    "    holdings_cols = bm_holdings_prices.columns\n",
    "    inferred_periods = [col for col in holdings_cols if 'returns' in col]\n",
    "    inferred_periods = [col.split('_')[1] for col in inferred_periods]\n",
    "    #rename bm_index_prices columns to have \"bm_returns_\" prefix. \n",
    "    bm_index_prices.columns = [col if col == \"Date\" else \"bm_\" + col for col in bm_index_prices.columns]\n",
    "    # print(bm_index_prices.head())\n",
    "    #merge the two dataframes on date left\n",
    "    merged = pd.merge(bm_holdings_prices, bm_index_prices, on=\"Date\", how=\"left\")\n",
    "    #calculate active returns\n",
    "    for period in inferred_periods:\n",
    "        merged[\"active_returns_\" + period] = merged[\"returns_\" + period] - merged[\"bm_returns_\" + period]\n",
    "    # print(merged.head())\n",
    "    \n",
    "    #TEST TO ENSURE THAT THE ACTIVE RETURNS ARE CORRECT AND SUMS TO WHEN ADDING BM RETURNS AND SUBTRACTING BM RETURNS\n",
    "    merged_for_testing = merged.copy()\n",
    "    merged_for_testing[\"TEST_COL\"] = merged_for_testing[\"active_returns_1b\"] + merged_for_testing[\"bm_returns_1b\"] - merged_for_testing[\"returns_1b\"]\n",
    "    merged_for_testing[\"TEST_COL\"] = merged_for_testing[\"TEST_COL\"].fillna(0)  # Replace NaNs with zeros for comparison\n",
    "    assert np.allclose(merged_for_testing[\"TEST_COL\"], 0), \"Active returns are not correctly calculated\"\n",
    "\n",
    "    #keep only (TICKER, Date, active_returns_*) columns\n",
    "    active_returns = merged[[\"Ticker\", \"Date\"] + [col for col in merged.columns if \"active_returns\" in col]]\n",
    "    return active_returns\n",
    "\n",
    "active_returns = get_active_returns(bm_index_prices_preproc, bm_holdings_prices_preproc)\n",
    "active_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_returns_thresholded = active_returns.copy()\n",
    "active_returns_thresholded = active_returns_thresholded.set_index([\"Ticker\", \"Date\"])\n",
    "active_returns_thresholded = active_returns_thresholded > (N_THRESHOLD_BPS / 10000)\n",
    "active_returns_thresholded = active_returns_thresholded.astype(float)\n",
    "active_returns_thresholded = active_returns_thresholded.reset_index()\n",
    "active_returns_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_returns_path = DATA_DIR + BM_NAME + \"_active_returns.csv\"\n",
    "active_returns.to_csv(active_returns_path)\n",
    "print(\"Active returns saved to \" + active_returns_path)\n",
    "active_returns_thresholded_path = DATA_DIR + BM_NAME + \"_active_returns_thresholded_\" + str(N_THRESHOLD_BPS) + \"bps.csv\"\n",
    "active_returns_thresholded.to_csv(active_returns_thresholded_path)\n",
    "print(\"Active returns thresholded saved to \" + active_returns_thresholded_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
